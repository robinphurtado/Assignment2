{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60e72d2",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Read all instructions carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda830bb",
   "metadata": {},
   "source": [
    "## Work Requirements\n",
    "\n",
    "- You must work on Assignment 2 alone. You may not work with partners.\n",
    "- You may use online resources (Stack Exchange, Googling, Regex cheat sheets), including documentation and everything on Canvas. However, you may not use an LLM (ChatGPT, Copilot, etc)\n",
    "- Lightly document your code, especially any decisions you make along the way. You do not need extensive documentation. You do **NOT** need a separate README file. But a person should be able to read your submission top to bottom and understand what you're doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c706db0",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "- This assignment is due on **Monday, October 6 at 6:59pm**.\n",
    "- The assignment must be submitted on Canvas as a single PDF file together with a requirements.txt file (as a text file, not PDF). The two files must be submitted as separate files, not as a zip file.\n",
    "- The PDF file you submit must be named with the following format \"lastname_firstname_assignment2.pdf\"\n",
    "- The requirements.txt file should only include the libraries you need to run your code in a Jupyter notebook, with their versions properly specified (e.g., use pip freeze with your venv activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cecea",
   "metadata": {},
   "source": [
    "## Recommendations and Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1b0ea",
   "metadata": {},
   "source": [
    "**Recommendation:** Complete the assignment in a Jupyter notebook, and then convert the notebook to a PDF. If you have too much trouble converting to PDF, then convert it to HTML, open it as HTML and export that page to PDF (but this is a less preferred option)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab2786",
   "metadata": {},
   "source": [
    "**Recommendation:** As always, start by examining the data you read in and understand it. What does each row represent in each dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30696280",
   "metadata": {},
   "source": [
    "**Helpful Documentation:**\n",
    "- Pandas expanding: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding\n",
    "- Python re library for Regex: https://docs.python.org/3/library/re.html\n",
    "- Pareto: https://numpy.org/doc/stable/reference/random/generated/numpy.random.pareto.html#numpy.random.pareto\n",
    "- Gaussian: https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy-random-normal\n",
    "- Seaborn Boxplot: https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "- Seaborn Scatterplot: https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "- Matplotlib scatterplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "- Matplotlib boxplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809f8a2",
   "metadata": {},
   "source": [
    "# Part 0 - Imports and CoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a43c1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd  # need to import pandas first.\n",
    "import re\n",
    "\n",
    "# Enforce Copy-on-Write\n",
    "pd.set_option(\"mode.copy_on_write\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2120e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "# import pandas as pd  -- imported above to run pd.set_option\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a9085f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set standard paths\n",
    "cwd = Path().cwd() #set our cwd\n",
    "project_folder = cwd.parent #set our project folder as the cwd parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455bbff",
   "metadata": {},
   "source": [
    "# Part 1 - Regex, EDA, and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a38bb2",
   "metadata": {},
   "source": [
    "Load the Food Safety datasets (bus.csv, ins2vio.csv, ins.csv, and vio.csv) into pandas dataframes and answer the following questions based on the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the datasets into Pandas DataFrames\n",
    "\n",
    "# df that holds the info regarding the buinesses\n",
    "bus_dataset_path = Path('data/bus.csv') #using a data folder makes life easier\n",
    "bus_file = project_folder / bus_dataset_path #join the project folder with the dataset path\n",
    "if not bus_file.exists():\n",
    "\traise FileNotFoundError(f\"Dataset file not found: {bus_file}\")\n",
    "\n",
    "# df that holds the info regarding the inspections\n",
    "ins_dataset_path = Path('data/ins.csv') #using a data folder makes life easier\n",
    "ins_file = project_folder / ins_dataset_path #join the project folder with the dataset path\n",
    "if not ins_file.exists():\n",
    "\traise FileNotFoundError(f\"Dataset file not found: {ins_file}\")\n",
    "\n",
    "# df that holds the relation from inspection to violation\n",
    "ins2vio_dataset_path = Path('data/ins2vio.csv') #using a data folder makes life easier\n",
    "ins2vio_file = project_folder / ins2vio_dataset_path #join the project folder with the dataset path\n",
    "if not ins2vio_file.exists():\n",
    "\traise FileNotFoundError(f\"Dataset file not found: {ins2vio_file}\")\n",
    "\n",
    "# df that holds the info regarding the violations\n",
    "vio_dataset_path = Path('data/vio.csv') #using a data folder makes life easier\n",
    "vio_file = project_folder / vio_dataset_path #join the project folder with the dataset path\n",
    "if not vio_file.exists():\n",
    "\traise FileNotFoundError(f\"Dataset file not found: {vio_file}\")\n",
    "\n",
    "business = pd.read_csv(bus_file)\n",
    "inspection = pd.read_csv(ins_file)\n",
    "insp2vio = pd.read_csv(ins2vio_file)\n",
    "violation = pd.read_csv(vio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549eb518",
   "metadata": {},
   "source": [
    "Use the business dataset (bus) to answer the first few questions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29e33f",
   "metadata": {},
   "source": [
    "1.1) Examining the entries in `bus`, is the `bid` unique for each record (i.e. each row of data)?\n",
    "\n",
    "Hint: use `value_counts()` or `unique()` to determine if the `bid` series has any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entries in the bid column of the bus file are unique:  True\n"
     ]
    }
   ],
   "source": [
    "# compare the number of elements in column with the number of unique elements in the column\n",
    "is_unique = business['business id column'].unique().size == business['business id column'].size\n",
    "print('The entries in the bid column of the bus file are unique: ', is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8de6b3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business id column</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>HEUNG YUEN RESTAURANT</td>\n",
       "      <td>3279 22nd St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94110</td>\n",
       "      <td>37.755282</td>\n",
       "      <td>-122.420493</td>\n",
       "      <td>-9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100010</td>\n",
       "      <td>ILLY CAFFE SF_PIER 39</td>\n",
       "      <td>PIER 39  K-106-B</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94133</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14154827284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100017</td>\n",
       "      <td>AMICI'S EAST COAST PIZZERIA</td>\n",
       "      <td>475 06th St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94103</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155279839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>LOCAL CATERING</td>\n",
       "      <td>1566 CARROLL AVE</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155860315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100030</td>\n",
       "      <td>OUI OUI! MACARON</td>\n",
       "      <td>2200 JERROLD AVE STE C</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94124</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14159702675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business id column                         name                 address  \\\n",
       "0                1000        HEUNG YUEN RESTAURANT            3279 22nd St   \n",
       "1              100010        ILLY CAFFE SF_PIER 39        PIER 39  K-106-B   \n",
       "2              100017  AMICI'S EAST COAST PIZZERIA             475 06th St   \n",
       "3              100026               LOCAL CATERING        1566 CARROLL AVE   \n",
       "4              100030             OUI OUI! MACARON  2200 JERROLD AVE STE C   \n",
       "\n",
       "            city state postal_code     latitude    longitude  phone_number  \n",
       "0  San Francisco    CA       94110    37.755282  -122.420493         -9999  \n",
       "1  San Francisco    CA       94133 -9999.000000 -9999.000000   14154827284  \n",
       "2  San Francisco    CA       94103 -9999.000000 -9999.000000   14155279839  \n",
       "3  San Francisco    CA       94124 -9999.000000 -9999.000000   14155860315  \n",
       "4  San Francisco    CA       94124 -9999.000000 -9999.000000   14159702675  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at the dataframe\n",
    "business.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94154de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business id column', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'phone_number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the columns of the business dataframe\n",
    "business.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "28f6f106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business id column</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6253.000000</td>\n",
       "      <td>6253.000000</td>\n",
       "      <td>6253.000000</td>\n",
       "      <td>6.253000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60448.948984</td>\n",
       "      <td>-5575.337966</td>\n",
       "      <td>-5645.817699</td>\n",
       "      <td>4.701819e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36480.132445</td>\n",
       "      <td>4983.390142</td>\n",
       "      <td>4903.993683</td>\n",
       "      <td>6.667508e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18399.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75685.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9.999000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90886.000000</td>\n",
       "      <td>37.776494</td>\n",
       "      <td>-122.421553</td>\n",
       "      <td>1.415533e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102705.000000</td>\n",
       "      <td>37.824494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.415988e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       business id column     latitude    longitude  phone_number\n",
       "count         6253.000000  6253.000000  6253.000000  6.253000e+03\n",
       "mean         60448.948984 -5575.337966 -5645.817699  4.701819e+09\n",
       "std          36480.132445  4983.390142  4903.993683  6.667508e+09\n",
       "min             19.000000 -9999.000000 -9999.000000 -9.999000e+03\n",
       "25%          18399.000000 -9999.000000 -9999.000000 -9.999000e+03\n",
       "50%          75685.000000 -9999.000000 -9999.000000 -9.999000e+03\n",
       "75%          90886.000000    37.776494  -122.421553  1.415533e+10\n",
       "max         102705.000000    37.824494     0.000000  1.415988e+10"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "business.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e23a73bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business id column      int64\n",
       "name                   object\n",
       "address                object\n",
       "city                   object\n",
       "state                  object\n",
       "postal_code            object\n",
       "latitude              float64\n",
       "longitude             float64\n",
       "phone_number            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd4c925",
   "metadata": {},
   "source": [
    "1.2) In the two cells below create the following **two numpy arrays**:\n",
    "\n",
    "1. Assign `top_names` to the top 5 most frequently used business names, from most frequent to least frequent.\n",
    "2. Assign `top_addresses` to the top 5 addressses where businesses are located, from most popular to least popular.\n",
    "\n",
    "Hint: you may find `value_counts()` helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f978b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the names with the 5 highest value counts as a numpy array top_names (value_counts returns a Series, names are the index)\n",
    "top_names = np.array(business['name'].value_counts().head().index) \n",
    "# store the addresses with the 5 highest value counts as a numpy array top_names (value_counts returns a Series, addresses are the index)\n",
    "top_addresses = np.array(business['address'].value_counts().head().index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c2c91",
   "metadata": {},
   "source": [
    "1.3) Look at the businesses that DO NOT have the special MISSING ZIP code value. Some of the invalid postal codes are just the full 9 digit code rather than the first 5 digits. Create a new column named `postal5` in the original bus dataframe which contains only the first 5 digits of the postal_code column. Finally, for any of the likely MISSING postal5 ZIP code entries set the entry to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d3daf865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postal_code\n",
       "94103         562\n",
       "94110         555\n",
       "94102         456\n",
       "94107         408\n",
       "94133         398\n",
       "             ... \n",
       "94124-1917      1\n",
       "94102-5917      1\n",
       "94105-2907      1\n",
       "95112           1\n",
       "94123-3106      1\n",
       "Name: count, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually explore postal_code column because it is not numeric\n",
    "business['postal_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6be62562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-9999'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['postal_code'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f6c66cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['94110', '94133', '94103', '94124', '94123', '94118', '94121',\n",
       "       '94134', '94114', '94109', '94102', '94132', '94116', '-9999',\n",
       "       '94107', '94105', '94108', '94117', '94158', '94112', '94127',\n",
       "       '94105-1420', '94111', '94122', '94115', '94104', '94122-1909',\n",
       "       '94131', '94117-3504', '94518', '95105', '94013', '94130',\n",
       "       '941102019', '941', '941033148', 'CA', '92672', '94120', '94143',\n",
       "       '94101', '94014', '94129', '94602', 'Ca', '94080', '00000',\n",
       "       '94188', '64110', '94544', '94301', '94901', '95117', '95133',\n",
       "       '95109', '95132', '95122', '94621', '94124-1917', '94102-5917',\n",
       "       '94105-2907', '95112', '94123-3106'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the unique postal codes to try and find special MISSING ZIP code value\n",
    "business['postal_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f896bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['94110', '94133', '94103', '94124', '94123', '94118', '94121',\n",
       "       '94134', '94114', '94109', '94102', '94132', '94116', '94107',\n",
       "       '94105', '94108', '94117', '94158', '94112', '94127', '94105-1420',\n",
       "       '94111', '94122', '94115', '94104', '94122-1909', '94131',\n",
       "       '94117-3504', '94518', '95105', '94013', '94130', '941102019',\n",
       "       '941', '941033148', 'CA', '92672', '94120', '94143', '94101',\n",
       "       '94014', '94129', '94602', 'Ca', '94080', '00000', '94188',\n",
       "       '64110', '94544', '94301', '94901', '95117', '95133', '95109',\n",
       "       '95132', '95122', '94621', '94124-1917', '94102-5917',\n",
       "       '94105-2907', '95112', '94123-3106'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3) Look at the businesses that DO NOT have the special MISSING ZIP code value. Some of the invalid \n",
    "# postal codes are just the full 9 digit code rather than the first 5 digits. Create a new column \n",
    "# named `postal5` in the original bus dataframe which contains only the first 5 digits of the \n",
    "# postal_code column. Finally, for any of the likely MISSING postal5 ZIP code entries set the entry to None.\n",
    "\n",
    "########################################\n",
    "\n",
    "# add the column postal5 as a copy of postal_code\n",
    "## business['postal5'] = business['postal_code']\n",
    "\n",
    "# if the value of postal5 is not '-9999' replace it with the first 5 digits\n",
    "# business['postal5'] != '-9999'\n",
    "## business['postal5'] = business[business['postal5'] != '-9999']['postal5'].str[:5]\n",
    "## business[business['postal5'] == '-9999']['postal5'].str.replace(business['postal5'], 'None')\n",
    "# pattern_pc = r\"([0-9]{5})\"\n",
    "# business['postal5'] = business['postal_code'].str[:5]\n",
    "# business[business['postal_code'].str.len() > 5]\n",
    "# business['postal_code'].is_na\n",
    "# ismissing = business['postal_code'] == '-9999'\n",
    "## isNone = business['postal5'] == 'None'\n",
    "## isNone.value_counts()\n",
    "\n",
    "########################3#########\n",
    "\n",
    "# look at the business that DO NOT have the special MISSING ZIP code value (-9999)\n",
    "# look at the unique values to see what we may have that is not the missign zip value and is not likely a valid zip\n",
    "business[business['postal_code'] != '-9999']['postal_code'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3ed1f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['94110', '94133', '94103', '94124', '94123', '94118', '94121',\n",
       "       '94134', '94114', '94109', '94102', '94132', '94116', 'None',\n",
       "       '94107', '94105', '94108', '94117', '94158', '94112', '94127',\n",
       "       '94111', '94122', '94115', '94104', '94131', '94518', '95105',\n",
       "       '94013', '94130', '941', 'CA', '92672', '94120', '94143', '94101',\n",
       "       '94014', '94129', '94602', 'Ca', '94080', '00000', '94188',\n",
       "       '64110', '94544', '94301', '94901', '95117', '95133', '95109',\n",
       "       '95132', '95122', '94621', '95112'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column  named `postal5` in the original bus dataframe which contains only the first 5 digits of the \n",
    "# postal_code column. \n",
    "business['postal5'] = business['postal_code'].str[:5]\n",
    "business\n",
    "business[business['postal_code'].str.len() > 5]\n",
    "\n",
    "# check to see if anything weird happened when we stored just the first 5 digits of postal_code in postal5\n",
    "business['postal5'].unique()\n",
    "\n",
    "# #Finally, for any of the likely MISSING postal5 ZIP code entries set the entry to None.\n",
    "# replace the zip codes that contanin the missing zip code value with 'None'\n",
    "business['postal5'] = business['postal5'].str.replace('-9999', 'None', regex = True)\n",
    "\n",
    "business['postal5'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108eab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business id column</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>postal5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>5208</td>\n",
       "      <td>GOLDEN GATE YACHT CLUB</td>\n",
       "      <td>1 YACHT Rd</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>941</td>\n",
       "      <td>37.807878</td>\n",
       "      <td>-122.442499</td>\n",
       "      <td>14155342628</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>64540</td>\n",
       "      <td>Leo's Hot Dogs</td>\n",
       "      <td>2301 Mission St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.760054</td>\n",
       "      <td>-122.419166</td>\n",
       "      <td>14155774013</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>64738</td>\n",
       "      <td>Japacurry</td>\n",
       "      <td>Public</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "      <td>37.777122</td>\n",
       "      <td>-122.419639</td>\n",
       "      <td>-9999</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>88139</td>\n",
       "      <td>Tacolicious</td>\n",
       "      <td>2250 Chestnut St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>Ca</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>14155646077</td>\n",
       "      <td>Ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      business id column                    name           address  \\\n",
       "1824                5208  GOLDEN GATE YACHT CLUB        1 YACHT Rd   \n",
       "2409               64540          Leo's Hot Dogs   2301 Mission St   \n",
       "2418               64738               Japacurry            Public   \n",
       "4576               88139             Tacolicious  2250 Chestnut St   \n",
       "\n",
       "               city state postal_code     latitude    longitude  phone_number  \\\n",
       "1824  San Francisco    CA         941    37.807878  -122.442499   14155342628   \n",
       "2409  San Francisco    CA          CA    37.760054  -122.419166   14155774013   \n",
       "2418  San Francisco    CA          CA    37.777122  -122.419639         -9999   \n",
       "4576  San Francisco    CA          Ca -9999.000000 -9999.000000   14155646077   \n",
       "\n",
       "     postal5  \n",
       "1824     941  \n",
       "2409      CA  \n",
       "2418      CA  \n",
       "4576      Ca  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the other odd values returned : 'CA', 'Ca', '00000', '941' not 5 digits\n",
    "pattern = r'^[0-9]{5}'\n",
    "business[~business['postal5'].str.match(pattern)] \n",
    "business[(business['postal5'] != 'None') & (~business['postal5'].str.match(pattern))] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7213255c",
   "metadata": {},
   "source": [
    "*I am not familiar enough with San Francisco or the zip code lat/ long areas to be able to speculate the correct zip codes here.  May be solved with a quick google for each restaurant and address, or go back to the source, but for now it would not be accurate to replace these postal codes with \"None\" because they were not missing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cb7a4f",
   "metadata": {},
   "source": [
    "Now using the four Food Safety datasets bus.csv, ins2vio.csv, ins.csv, and vio.csv:\n",
    "\n",
    "1.5) Create a side-by-side boxplot that shows the distribution of the restaurant scores for each different risk category from 2017 to 2019. Use a figure size of at least 12 by 8.\n",
    "\n",
    "Hint: Consider using appropriate JOIN operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9d9719bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>vid</th>\n",
       "      <th>date</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>risk_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14238</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103161</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>Low risk vermin infestation</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14579</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103154</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>Unclean or degraded floors walls or ceilings</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16391</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103142</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>Unclean nonfood contact surfaces</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23089</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103132</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>Improper thawing methods</td>\n",
       "      <td>Moderate Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29438</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103139</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>Improper food storage</td>\n",
       "      <td>Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31862</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103109</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>Unclean or unsanitary food contact surfaces</td>\n",
       "      <td>High Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40023</th>\n",
       "      <td>1000_20171002</td>\n",
       "      <td>103103</td>\n",
       "      <td>10/02/2017 12:00:00 AM</td>\n",
       "      <td>74</td>\n",
       "      <td>Routine - Unscheduled</td>\n",
       "      <td>High risk food holding temperature</td>\n",
       "      <td>High Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 iid     vid                    date  score  \\\n",
       "14238  1000_20171002  103161  10/02/2017 12:00:00 AM     74   \n",
       "14579  1000_20171002  103154  10/02/2017 12:00:00 AM     74   \n",
       "16391  1000_20171002  103142  10/02/2017 12:00:00 AM     74   \n",
       "23089  1000_20171002  103132  10/02/2017 12:00:00 AM     74   \n",
       "29438  1000_20171002  103139  10/02/2017 12:00:00 AM     74   \n",
       "31862  1000_20171002  103109  10/02/2017 12:00:00 AM     74   \n",
       "40023  1000_20171002  103103  10/02/2017 12:00:00 AM     74   \n",
       "\n",
       "                        type                                   description  \\\n",
       "14238  Routine - Unscheduled                   Low risk vermin infestation   \n",
       "14579  Routine - Unscheduled  Unclean or degraded floors walls or ceilings   \n",
       "16391  Routine - Unscheduled              Unclean nonfood contact surfaces   \n",
       "23089  Routine - Unscheduled                      Improper thawing methods   \n",
       "29438  Routine - Unscheduled                         Improper food storage   \n",
       "31862  Routine - Unscheduled   Unclean or unsanitary food contact surfaces   \n",
       "40023  Routine - Unscheduled            High risk food holding temperature   \n",
       "\n",
       "       risk_category  \n",
       "14238       Low Risk  \n",
       "14579       Low Risk  \n",
       "16391       Low Risk  \n",
       "23089  Moderate Risk  \n",
       "29438       Low Risk  \n",
       "31862      High Risk  \n",
       "40023      High Risk  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SELECT\n",
    "# i.score,\n",
    "# v.risk_category\n",
    "#FROM\n",
    "#viol v\n",
    "#INNER JOIN\n",
    "# ins2vio i2v  ON v.vid = i2v.vid\n",
    "# INNER JOIN\n",
    "# ins i IN i2v.iid=i.iid\n",
    "#WHERE\n",
    "#need to filter dates from 2017-2019\n",
    "score_dist_2017to2019 = insp2vio.merge(inspection, how='left')\n",
    "score_dist_2017to2019\n",
    "score_dist_2017to2019[score_dist_2017to2019['iid'] == '1000_20171002']\n",
    "score_dist_2017to2019 = score_dist_2017to2019.merge(violation)\n",
    "score_dist_2017to2019\n",
    "score_dist_2017to2019[score_dist_2017to2019['iid'] == '1000_20171002']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ce096",
   "metadata": {},
   "source": [
    "# Part II - Making a Synthetic Dataset\n",
    "\n",
    "In this part you're going to be create a synthetic dataset (dataframe) with 1000 observations (rows). You are going to use random number generators to create the data for you.\n",
    "\n",
    "You can use either the numpy or scipy library, whichever you find easier. Be sure to import any libraries you use at the top of the ntoebook (not down here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d9f14f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e272b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: set random seed for reproducibility (how you do it depends on whether yo uuse numpy or scipy to generate the random numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951e7b7",
   "metadata": {},
   "source": [
    "2.1) Create a variable \"v1\" of 10,000 numbers where y = 3x+4 is the value of the element at index x, i.e., [4, 7, 10, ...] (Done for you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ab0d3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 3 * np.arange(n) + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bf94e",
   "metadata": {},
   "source": [
    "2.2) Create a list of 10,000 samples from a normal (Gaussian) distribution with mean = 0 and variance = 10.\n",
    "\n",
    "HINT: Pay attention to whether the argument to your number generator is variance or standard deviation. (It doesn't have to be a python list, it can be an array or dataframe, or whatever dtype is most convenient for you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d8ffefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = np.random.normal... (can also use scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d70539",
   "metadata": {},
   "source": [
    "2.3) Create a variable v2 = v1 + Gaussian noise, using the noise your created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa5af276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 = v1 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df85a53",
   "metadata": {},
   "source": [
    "2.4) Create a variable v3 = exp(v1) that exponentiates the libear variable in v1, also sometimes denoted e^(v1), e.g., v3[0] = e^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3d1d1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v3 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285be5f",
   "metadata": {},
   "source": [
    "2.5) Create a list v4 = exp(v1) + Gaussian noise, using the same noise variable you created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "789c7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc92013",
   "metadata": {},
   "source": [
    "2.6) Create a list v5 = exp(v1 + Gaussian noise), using the same noise variable you created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea33d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v5 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b34357",
   "metadata": {},
   "source": [
    "2.7) Create a dataframe with 10,000 rows and columns = [v1, v2, v3, v4, v5, noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d819f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a25983",
   "metadata": {},
   "source": [
    "2.8) For each variable (v2, v3, v4, v5) create a separate scatter plot with v1 on the x-axis. Remark on your general observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "64cc6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plots here, and remarks and observations here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbf13a",
   "metadata": {},
   "source": [
    "2.9)  Create pair of boxplots with v4 and v5 next to each other. Remark on how v4 and v5 compare, based on the violin plots and the scatter plots. You may use other plots or tools if helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804372e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52d9ba9f",
   "metadata": {},
   "source": [
    "## Part III - Sampling and Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9198364",
   "metadata": {},
   "source": [
    "3.1) Create a variable \"pareto\" that is a list of 10,000 samples from a Pareto distribution with shape parameter = 1.2 (usually denoted a or alpha). Add this list \"pareto\" as a column to your dataframe from Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1da7dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pareto = np.random.pareto... (can also use scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a2ec6",
   "metadata": {},
   "source": [
    "3.2) Add two more columns to your dataframe labeled \"running_avg_normal\" and \"running_avg_pareto\". In the \"running_avg_normal\" column put the running average of the (unsorted) values in the noise column. For example, if the values in the noise column are [0.1, 0.3, 0.5, ...] then the running average should be [0.1, 0.2, 0.3, ...]. Do the same for the Pareto column.\n",
    "\n",
    "HINT: Check out the .expanding() and .mean() methods for pandas Series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235e689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cecaf5e",
   "metadata": {},
   "source": [
    "3.3) Create a lineplot for running_avg_normal and a lineplot for running_avg_Pareto. Remark on your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f16ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
