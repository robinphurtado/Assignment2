{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60e72d2",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "Read all instructions carefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda830bb",
   "metadata": {},
   "source": [
    "## Work Requirements\n",
    "\n",
    "- You must work on Assignment 2 alone. You may not work with partners.\n",
    "- You may use online resources (Stack Exchange, Googling, Regex cheat sheets), including documentation and everything on Canvas. However, you may not use an LLM (ChatGPT, Copilot, etc)\n",
    "- Lightly document your code, especially any decisions you make along the way. You do not need extensive documentation. You do **NOT** need a separate README file. But a person should be able to read your submission top to bottom and understand what you're doing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c706db0",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "- This assignment is due on **Monday, October 6 at 6:59pm**.\n",
    "- The assignment must be submitted on Canvas as a single PDF file together with a requirements.txt file (as a text file, not PDF). The two files must be submitted as separate files, not as a zip file.\n",
    "- The PDF file you submit must be named with the following format \"lastname_firstname_assignment2.pdf\"\n",
    "- The requirements.txt file should only include the libraries you need to run your code in a Jupyter notebook, with their versions properly specified (e.g., use pip freeze with your venv activated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7cecea",
   "metadata": {},
   "source": [
    "## Recommendations and Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1b0ea",
   "metadata": {},
   "source": [
    "**Recommendation:** Complete the assignment in a Jupyter notebook, and then convert the notebook to a PDF. If you have too much trouble converting to PDF, then convert it to HTML, open it as HTML and export that page to PDF (but this is a less preferred option)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab2786",
   "metadata": {},
   "source": [
    "**Recommendation:** As always, start by examining the data you read in and understand it. What does each row represent in each dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30696280",
   "metadata": {},
   "source": [
    "**Helpful Documentation:**\n",
    "- Pandas expanding: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding\n",
    "- Python re library for Regex: https://docs.python.org/3/library/re.html\n",
    "- Pareto: https://numpy.org/doc/stable/reference/random/generated/numpy.random.pareto.html#numpy.random.pareto\n",
    "- Gaussian: https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html#numpy-random-normal\n",
    "- Seaborn Boxplot: https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "- Seaborn Scatterplot: https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "- Matplotlib scatterplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html\n",
    "- Matplotlib boxplot: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.boxplot.html#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809f8a2",
   "metadata": {},
   "source": [
    "# Part 0 - Imports and CoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a43c1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce Copy-on-Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2120e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455bbff",
   "metadata": {},
   "source": [
    "# Part 1 - Regex, EDA, and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a38bb2",
   "metadata": {},
   "source": [
    "Load the Food Safety datasets (bus.csv, ins2vio.csv, ins.csv, and vio.csv) into pandas dataframes and answer the following questions based on the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "932d1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the datasets into Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549eb518",
   "metadata": {},
   "source": [
    "Use the business dataset (bus) to answer the first few questions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29e33f",
   "metadata": {},
   "source": [
    "1.1) Examining the entries in `bus`, is the `bid` unique for each record (i.e. each row of data)?\n",
    "\n",
    "Hint: use `value_counts()` or `unique()` to determine if the `bid` series has any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6f106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd4c925",
   "metadata": {},
   "source": [
    "1.2) In the two cells below create the following **two numpy arrays**:\n",
    "\n",
    "1. Assign `top_names` to the top 5 most frequently used business names, from most frequent to least frequent.\n",
    "2. Assign `top_addresses` to the top 5 addressses where businesses are located, from most popular to least popular.\n",
    "\n",
    "Hint: you may find `value_counts()` helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978b994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd7c2c91",
   "metadata": {},
   "source": [
    "1.3) Look at the businesses that DO NOT have the special MISSING ZIP code value. Some of the invalid postal codes are just the full 9 digit code rather than the first 5 digits. Create a new column named `postal5` in the original bus dataframe which contains only the first 5 digits of the postal_code column. Finally, for any of the likely MISSING postal5 ZIP code entries set the entry to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f896bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23cb7a4f",
   "metadata": {},
   "source": [
    "Now using the four Food Safety datasets bus.csv, ins2vio.csv, ins.csv, and vio.csv:\n",
    "\n",
    "1.5) Create a side-by-side boxplot that shows the distribution of the restaurant scores for each different risk category from 2017 to 2019. Use a figure size of at least 12 by 8.\n",
    "\n",
    "Hint: Consider using appropriate JOIN operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ce096",
   "metadata": {},
   "source": [
    "# Part II - Making a Synthetic Dataset\n",
    "\n",
    "In this part you're going to be create a synthetic dataset (dataframe) with 1000 observations (rows). You are going to use random number generators to create the data for you.\n",
    "\n",
    "You can use either the numpy or scipy library, whichever you find easier. Be sure to import any libraries you use at the top of the ntoebook (not down here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9f14f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e272b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: set random seed for reproducibility (how you do it depends on whether yo uuse numpy or scipy to generate the random numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951e7b7",
   "metadata": {},
   "source": [
    "2.1) Create a variable \"v1\" of 10,000 numbers where y = 3x+4 is the value of the element at index x, i.e., [4, 7, 10, ...] (Done for you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 3 * np.arange(n) + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305bf94e",
   "metadata": {},
   "source": [
    "2.2) Create a list of 10,000 samples from a normal (Gaussian) distribution with mean = 0 and variance = 10.\n",
    "\n",
    "HINT: Pay attention to whether the argument to your number generator is variance or standard deviation. (It doesn't have to be a python list, it can be an array or dataframe, or whatever dtype is most convenient for you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ffefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = np.random.normal... (can also use scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d70539",
   "metadata": {},
   "source": [
    "2.3) Create a variable v2 = v1 + Gaussian noise, using the noise your created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5af276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.54113104e+00 8.89003362e+00 5.74110015e+00 ... 2.99888405e+04\n",
      " 2.99972317e+04 3.00028569e+04]\n"
     ]
    }
   ],
   "source": [
    "# v2 = v1 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df85a53",
   "metadata": {},
   "source": [
    "2.4) Create a variable v3 = exp(v1) that exponentiates the libear variable in v1, also sometimes denoted e^(v1), e.g., v3[0] = e^4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v3 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285be5f",
   "metadata": {},
   "source": [
    "2.5) Create a list v4 = exp(v1) + Gaussian noise, using the same noise variable you created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "789c7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc92013",
   "metadata": {},
   "source": [
    "2.6) Create a list v5 = exp(v1 + Gaussian noise), using the same noise variable you created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea33d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v5 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b34357",
   "metadata": {},
   "source": [
    "2.7) Create a dataframe with 10,000 rows and columns = [v1, v2, v3, v4, v5, noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d819f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a25983",
   "metadata": {},
   "source": [
    "2.8) For each variable (v2, v3, v4, v5) create a separate scatter plot with v1 on the x-axis. Remark on your general observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64cc6b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plots here, and remarks and observations here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcbf13a",
   "metadata": {},
   "source": [
    "2.9)  Create pair of boxplots with v4 and v5 next to each other. Remark on how v4 and v5 compare, based on the violin plots and the scatter plots. You may use other plots or tools if helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804372e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52d9ba9f",
   "metadata": {},
   "source": [
    "## Part III - Sampling and Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9198364",
   "metadata": {},
   "source": [
    "3.1) Create a variable \"pareto\" that is a list of 10,000 samples from a Pareto distribution with shape parameter = 1.2 (usually denoted a or alpha). Add this list \"pareto\" as a column to your dataframe from Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pareto = np.random.pareto... (can also use scipy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280a2ec6",
   "metadata": {},
   "source": [
    "3.2) Add two more columns to your dataframe labeled \"running_avg_normal\" and \"running_avg_pareto\". In the \"running_avg_normal\" column put the running average of the (unsorted) values in the noise column. For example, if the values in the noise column are [0.1, 0.3, 0.5, ...] then the running average should be [0.1, 0.2, 0.3, ...]. Do the same for the Pareto column.\n",
    "\n",
    "HINT: Check out the .expanding() and .mean() methods for pandas Series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9235e689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cecaf5e",
   "metadata": {},
   "source": [
    "3.3) Create a lineplot for running_avg_normal and a lineplot for running_avg_Pareto. Remark on your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f16ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
